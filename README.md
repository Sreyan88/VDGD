# VDGD

## Infering using LVLMs
```
cd inference_files/

LLaVA -
python llava_inference.py <model_path> <dataset_name> <output_file_name> <sampling_flag>

python llava_v1_inference.py <dataset_name> <output_file_name> <sampling_flag>

CogVLM -
python cogvlm_inference.py <dataset_name> <output_file_name>

MplugOwl2 -
python mlpug_owl2_inference.py <dataset_name> <output_file_name> <sampling_flag>

InternLM -
python internlm_inference.py <dataset_name> <output_file_name> <sampling_flag>

Examples -
python llava_inference.py liuhaotian/llava-v1.6-vicuna-7b amber llava_16_amber 0
python llava_v1_inference.py amber llava_v1_amber 0
python cogvlm_inference.py amber cogvlm_amber

Supported Arugments:
1. model_path - this argument is only for llava 1.5 or 1.6 inference file.

2. dataset_name - file prefix in the `datasets/` folder.

3. output_file_name - output file name which will be saved at `inference_generations`.

4. sampling_flag - A 1 or 0 value which will set sampling arguments for inference.
```

## GPT evaluation of LVLM inference
```
cd gpt_evaluations/
python evaluate_gpt.py <inference_file_name>

Supported Arugments:
1. inference_file_name - file prefix of LVLM output in `inference_generations`.
```

## Logit Analysis of LVLMs
```
cd AlignTDS/ 
sh run.sh <llm_model_name> <shard_size> <num_gpus> <model_generated_dataset_name> <dataset_length>

Example - sh run.sh llava_1.6 126 8 llava_1.6_amber 1004

Supported arguments:
1. llm_model_name - llava_v1, llava_1.5, llava_1.6, cogvlm.

2. shard_size - dataset_length/num_gpus.

3. model_generated_dataset_name - this argument is the name of the file to run logit analysis for in ./AlignTDS/data/.
```

## Categorizing Visual Hallucinations

```
cd hallucination_categorization/

For MMMU Openended generation:
python gpt_precent_hallucinations_mmmu.py <model_generated_dataset_name> <object_file_path> <gpt_eval_file_name>

For Amber generation:
python gpt_precent_hallucinations_amber.py <model_generated_dataset_name> <object_file_path> <gpt_eval_file_name>

Supported arguments:
1. model_generated_dataset_name - this is the same argument used in Logit Analysis section above.

2. object_file_path - this file is generated by prompting Llama 3 using(note LVLMs have to generate image descriptions first):
I will provide you with a response from an AI agent which has been asked to describe an image. Please identify all the phrases that in the image description that constitute the image. These phrases might be foreground and background objects, adverbial phrases, etc. Return them as comma separated values. There should not be any additional information other than these values in the output. The response is as follows: {response}.

3. gpt_eval_file_name - this is the same argument as <inference_file_name> in GPT Evaluation section.
```

## VDGD Inference